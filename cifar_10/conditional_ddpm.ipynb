{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conditional DDPM on CIFAR-10 dataset** \n",
    "\n",
    "This notebook trains a classifier-free conditional DDPM on the CIFAR-10 dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device and hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 128\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0002\n",
    "beta_start = 0.0001\n",
    "beta_end = 0.02\n",
    "timesteps = 1000\n",
    "num_classes = 10\n",
    "dropout_prob = 0.1\n",
    "base_channels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root='./data', train=True, transform=transform, download=True\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Complex Conditional U-Net\n",
    "class ConditionalUNet(nn.Module):\n",
    "    def __init__(self, num_classes, base_channels=64):\n",
    "        super(ConditionalUNet, self).__init__()\n",
    "        \n",
    "        # Class embedding\n",
    "        self.class_emb = nn.Embedding(num_classes + 1, base_channels)\n",
    "        \n",
    "        # Encoder\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(1, base_channels, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels * 2, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Middle\n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.up1 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4 + base_channels, base_channels * 2, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.up2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2 + base_channels, base_channels, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.final = nn.Conv2d(base_channels, 1, 1)\n",
    "        \n",
    "    def forward(self, x, class_labels):\n",
    "        class_emb = self.class_emb(class_labels).unsqueeze(-1).unsqueeze(-1)\n",
    "        \n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool1(e1)\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool2(e2)\n",
    "        \n",
    "        m = self.middle(p2)\n",
    "        \n",
    "        u1 = self.up1(m)\n",
    "        class_emb_resized = class_emb.expand(-1, -1, u1.shape[2], u1.shape[3])\n",
    "        d1_input = torch.cat([u1, e2, class_emb_resized], dim=1)\n",
    "        d1 = self.dec1(d1_input)\n",
    "        \n",
    "        u2 = self.up2(d1)\n",
    "        class_emb_resized = class_emb.expand(-1, -1, u2.shape[2], u2.shape[3])\n",
    "        d2_input = torch.cat([u2, e1, class_emb_resized], dim=1)\n",
    "        d2 = self.dec2(d2_input)\n",
    "        \n",
    "        return torch.tanh(self.final(d2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion schedule\n",
    "def get_betas(timesteps):\n",
    "    betas = torch.linspace(beta_start, beta_end, timesteps)\n",
    "    return betas.to(device)\n",
    "\n",
    "def get_alphas(betas):\n",
    "    alphas = 1.0 - betas\n",
    "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "    return alphas, alphas_cumprod\n",
    "\n",
    "def q_sample(x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "    \n",
    "    betas = get_betas(timesteps)\n",
    "    alphas, alphas_cumprod = get_alphas(betas)\n",
    "    \n",
    "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod[t])\n",
    "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod[t])\n",
    "    \n",
    "    return (sqrt_alphas_cumprod * x_start + \n",
    "            sqrt_one_minus_alphas_cumprod * noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "model = ConditionalUNet(num_classes, base_channels).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "betas = get_betas(timesteps)\n",
    "alphas, alphas_cumprod = get_alphas(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            batch_size = images.shape[0]\n",
    "            \n",
    "            t = torch.randint(0, timesteps, (batch_size,), device=device)\n",
    "            mask = (torch.rand(batch_size, device=device) > dropout_prob).long()\n",
    "            conditioned_labels = labels * mask + (1 - mask) * num_classes\n",
    "            \n",
    "            noise = torch.randn_like(images)\n",
    "            x_noisy = q_sample(images, t, noise)\n",
    "            predicted_noise = model(x_noisy, conditioned_labels)\n",
    "            \n",
    "            loss = criterion(predicted_noise, noise)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if i % 100 == 0:\n",
    "                print(f'Epoch [{epoch}/{num_epochs}], Step [{i}/{len(train_loader)}], '\n",
    "                      f'Loss: {loss.item():.4f}')\n",
    "        \n",
    "        # Average loss for the epoch\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "    \n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Plot training loss\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, num_epochs + 1), losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Average Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional sampling with trajectory\n",
    "@torch.no_grad()\n",
    "def sample_conditional(model, num_samples=1, class_label=None, guidance_scale=3.0, save_trajectory=False):\n",
    "    model.eval()\n",
    "    x = torch.randn(num_samples, 1, 28, 28).to(device)\n",
    "    \n",
    "    if class_label is None:\n",
    "        labels = torch.arange(num_samples) % num_classes\n",
    "    else:\n",
    "        labels = torch.full((num_samples,), class_label, dtype=torch.long)\n",
    "    labels = labels.to(device)\n",
    "    null_labels = torch.full((num_samples,), num_classes, dtype=torch.long).to(device)\n",
    "    \n",
    "    trajectory = [x.cpu().numpy()] if save_trajectory else None\n",
    "    \n",
    "    for t in reversed(range(timesteps)):\n",
    "        t_tensor = torch.full((num_samples,), t, device=device)\n",
    "        pred_noise_cond = model(x, labels)\n",
    "        pred_noise_uncond = model(x, null_labels)\n",
    "        predicted_noise = pred_noise_uncond + guidance_scale * (pred_noise_cond - pred_noise_uncond)\n",
    "        \n",
    "        betas_t = betas[t]\n",
    "        alphas_t = alphas[t]\n",
    "        alphas_cumprod_t = alphas_cumprod[t]\n",
    "        \n",
    "        x = (1 / torch.sqrt(alphas_t)) * (\n",
    "            x - ((1 - alphas_t) / torch.sqrt(1 - alphas_cumprod_t)) * predicted_noise\n",
    "        )\n",
    "        \n",
    "        if t > 0:\n",
    "            x = x + torch.sqrt(betas_t) * torch.randn_like(x)\n",
    "        \n",
    "        if save_trajectory and t % 100 == 0:\n",
    "            trajectory.append(x.cpu().numpy())\n",
    "    \n",
    "    return x, trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Samples for different class conditions\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "for i in range(10):\n",
    "    samples, _ = sample_conditional(model, num_samples=1, class_label=i)\n",
    "    samples = samples.cpu().numpy()\n",
    "    ax = axes[i // 5, i % 5]\n",
    "    ax.imshow(samples[0, 0], cmap='gray')\n",
    "    ax.set_title(f'Digit {i}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Samples for Each Class\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Trajectory for digit 5\n",
    "samples, trajectory = sample_conditional(model, num_samples=1, class_label=5, save_trajectory=True)\n",
    "trajectory = np.concatenate(trajectory, axis=0)\n",
    "\n",
    "fig, axes = plt.subplots(1, len(trajectory), figsize=(15, 3))\n",
    "for i, (img, ax) in enumerate(zip(trajectory, axes)):\n",
    "    ax.imshow(img[0, 0], cmap='gray')\n",
    "    ax.set_title(f'Step {timesteps - (i * 100)}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Trajectory from Noise to Digit 5\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4: Samples with different guidance scales for digit 5\n",
    "guidance_scales = [0.0, 1.0, 2.0, 3.0, 5.0]\n",
    "fig, axes = plt.subplots(1, len(guidance_scales), figsize=(15, 3))\n",
    "\n",
    "for i, scale in enumerate(guidance_scales):\n",
    "    samples, _ = sample_conditional(model, num_samples=1, class_label=5, guidance_scale=scale)\n",
    "    samples = samples.cpu().numpy()\n",
    "    ax = axes[i]\n",
    "    ax.imshow(samples[0, 0], cmap='gray')\n",
    "    ax.set_title(f'Guidance Scale: {scale}')\n",
    "    ax.axis('off')\n",
    "plt.suptitle(\"Effect of Guidance Scale on Digit 5\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flow-diffusion-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
