{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "from tqdm import tqdm \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Lambda(lambda x: x * 2. - 1.)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb95e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module): \n",
    "    def __init__(self, in_channels=3, base_channels=64, num_classes=10, cond_dropout=0.1): \n",
    "        super().__init__()\n",
    "        self.cond_dropout = cond_dropout\n",
    "        self.label_emb = nn.Embedding(num_classes, 1)\n",
    "\n",
    "        # Downsampling path \n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels + 2, base_channels, 3, padding=1), nn.ReLU(), \n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels, base_channels * 2, 3, padding=1), nn.ReLU(),\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottleneck \n",
    "        self.middle = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels * 4, 3, padding=1), nn.ReLU(), \n",
    "            nn.Conv2d(base_channels * 4, base_channels * 4, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Upsampling path \n",
    "        self.up1 = nn.ConvTranspose2d(base_channels * 4, base_channels * 2, 2, stride=2)\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 4, base_channels * 2, 3, padding=1), nn.ReLU(), \n",
    "            nn.Conv2d(base_channels * 2, base_channels * 2, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(base_channels * 2, base_channels, 2, stride=2)\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.Conv2d(base_channels * 2, base_channels, 3, padding=1), nn.ReLU(), \n",
    "            nn.Conv2d(base_channels, base_channels, 3, padding=1), nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.final = nn.Conv2d(base_channels, in_channels, 1)\n",
    "        \n",
    "    def forward(self, x, t, y=None): \n",
    "        # Time embedding\n",
    "        t = t[:, None, None, None].repeat(1, 1, x.shape[2], x.shape[3])\n",
    "        \n",
    "        # Classifier-free dropout\n",
    "        if y is not None and torch.rand(1).item() < self.cond_dropout:\n",
    "            y = None\n",
    "        y_emb = self.label_emb(y) if y is not None else torch.zeros(x.size(0), 1, device=x.device)\n",
    "        y_emb = y_emb[:, :, None, None].repeat(1, 1, x.shape[2], x.shape[3])\n",
    "\n",
    "        x = torch.cat([x, t, y_emb], dim=1)\n",
    "\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        mid = self.middle(self.pool2(e2))\n",
    "\n",
    "        d1 = self.up1(mid)\n",
    "        d1 = self.dec1(torch.cat([d1, e2], dim=1))\n",
    "\n",
    "        d2 = self.up2(d1)\n",
    "        d2 = self.dec2(torch.cat([d2, e1], dim=1))\n",
    "\n",
    "        return self.final(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c674d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 1e-4\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "T = 1000\n",
    "betas = linear_beta_schedule(T).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod)\n",
    "\n",
    "def q_sample(x_start, t, noise):\n",
    "    return sqrt_alphas_cumprod[t][:, None, None, None] * x_start +            sqrt_one_minus_alphas_cumprod[t][:, None, None, None] * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cdb1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "\n",
    "for epoch in range(5):  # reduce for demonstration\n",
    "    model.train()\n",
    "    for x, y in tqdm(train_loader):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        t = torch.randint(0, T, (x.size(0),), device=device).long()\n",
    "        noise = torch.randn_like(x)\n",
    "        x_t = q_sample(x, t, noise)\n",
    "        pred = model(x_t, t, y)\n",
    "        loss = F.mse_loss(pred, noise)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1} loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def p_sample(model, x, t, y, guidance_scale=5.0):\n",
    "    eps_cond = model(x, t, y)\n",
    "    eps_uncond = model(x, t, None)\n",
    "    eps = (1 + guidance_scale) * eps_cond - guidance_scale * eps_uncond\n",
    "    alpha_t = alphas[t][:, None, None, None]\n",
    "    alpha_bar_t = alphas_cumprod[t][:, None, None, None]\n",
    "    beta_t = betas[t][:, None, None, None]\n",
    "    sqrt_one_minus_alpha_bar_t = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "    sqrt_recip_alpha_bar_t = (1. / sqrt_alphas_cumprod[t])[:, None, None, None]\n",
    "\n",
    "    x0_pred = (x - sqrt_one_minus_alpha_bar_t * eps) / sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "    mean = (1 / torch.sqrt(alpha_t)) * (x - beta_t * eps / sqrt_one_minus_alpha_bar_t)\n",
    "    if t[0] == 0:\n",
    "        return x0_pred\n",
    "    noise = torch.randn_like(x)\n",
    "    return mean + torch.sqrt(beta_t) * noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e9163",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def sample_ddpm(model, label, guidance_scale=5.0):\n",
    "    model.eval()\n",
    "    x = torch.randn((16, 3, 32, 32)).to(device)\n",
    "    imgs = []\n",
    "    for t_val in reversed(range(T)):\n",
    "        t = torch.tensor([t_val] * x.size(0)).to(device)\n",
    "        x = p_sample(model, x, t, torch.tensor([label] * x.size(0)).to(device), guidance_scale)\n",
    "        if t_val % 100 == 0:\n",
    "            imgs.append(x.clamp(-1, 1).cpu())\n",
    "    return imgs\n",
    "\n",
    "# Generate and visualize with different guidance scales\n",
    "scales = [0.0, 2.5, 5.0]\n",
    "fig, axs = plt.subplots(len(scales), 5, figsize=(15, 9))\n",
    "\n",
    "for i, scale in enumerate(scales):\n",
    "    imgs = sample_ddpm(model, label=3, guidance_scale=scale)\n",
    "    for j in range(5):\n",
    "        grid = make_grid(imgs[j], nrow=4, normalize=True, value_range=(-1, 1))\n",
    "        axs[i, j].imshow(grid.permute(1, 2, 0))\n",
    "        axs[i, j].set_title(f\"t={T - j * 100}\")\n",
    "        axs[i, j].axis('off')\n",
    "    axs[i, 0].set_ylabel(f\"Scale={scale}\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad3bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def sample_multiple_classes(model, labels, guidance_scale=5.0):\n",
    "    model.eval()\n",
    "    n = len(labels)\n",
    "    x = torch.randn((n, 3, 32, 32)).to(device)\n",
    "    for t_val in reversed(range(T)):\n",
    "        t = torch.tensor([t_val] * n).to(device)\n",
    "        x = p_sample(model, x, t, torch.tensor(labels).to(device), guidance_scale)\n",
    "    return x.clamp(-1, 1).cpu()\n",
    "\n",
    "# Visualize samples for all 10 CIFAR-10 classes\n",
    "label_names = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "labels = list(range(10))\n",
    "samples = sample_multiple_classes(model, labels, guidance_scale=5.0)\n",
    "\n",
    "fig, axs = plt.subplots(1, 10, figsize=(15, 2))\n",
    "for i, img in enumerate(samples):\n",
    "    axs[i].imshow((img.permute(1, 2, 0) + 1) / 2)\n",
    "    axs[i].set_title(label_names[i], fontsize=9)\n",
    "    axs[i].axis('off')\n",
    "plt.suptitle(\"Classifier-Free Guidance Samples (1 per class)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b9f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def visualize_trajectory(model, label=3, guidance_scale=5.0):\n",
    "    x = torch.randn((1, 3, 32, 32)).to(device)\n",
    "    trajectory = []\n",
    "\n",
    "    for t_val in reversed(range(T)):\n",
    "        t = torch.tensor([t_val]).to(device)\n",
    "        x = p_sample(model, x, t, torch.tensor([label]).to(device), guidance_scale)\n",
    "        if t_val % 100 == 0 or t_val in [0, T-1]:\n",
    "            trajectory.append(x.squeeze().clamp(-1, 1).cpu())\n",
    "\n",
    "    # Plot\n",
    "    fig, axs = plt.subplots(1, len(trajectory), figsize=(18, 2))\n",
    "    for i, img in enumerate(trajectory):\n",
    "        axs[i].imshow((img.permute(1, 2, 0) + 1) / 2)\n",
    "        axs[i].set_title(f\"t={T - i*100}\")\n",
    "        axs[i].axis(\"off\")\n",
    "    plt.suptitle(\"Sampling Trajectory for One Image\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize\n",
    "visualize_trajectory(model, label=3, guidance_scale=5.0)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
